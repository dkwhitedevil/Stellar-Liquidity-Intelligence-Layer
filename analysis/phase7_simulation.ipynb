{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0612611e",
   "metadata": {},
   "source": [
    "# Phase 7 â€” Simulation & Comparison: SLIL vs baseline routing\n",
    "\n",
    "This notebook runs a deterministic, reproducible Monte Carlo simulation to compare standard Stellar pathfinding against SLIL-assisted routing. It generates synthetic graphs with annotated edge signals (depth, spread, volatility, failure_rate), runs many simulated transactions, and reports metrics such as success rate and average slippage.\n",
    "\n",
    "DONE criteria:\n",
    "- Produce a reproducible comparison showing improved success rate and/or lower slippage for SLIL-assisted routing on the synthetic dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0d157c",
   "metadata": {},
   "source": [
    "## 1) Environment & Dependencies\n",
    "\n",
    "This notebook uses Python 3 and the project's backend code. Required libraries:\n",
    "\n",
    "- numpy, pandas, matplotlib, networkx\n",
    "\n",
    "Install (backend virtualenv):\n",
    "\n",
    "```bash\n",
    "python3 -m pip install -r backend/requirements.txt\n",
    "python3 -m pip install matplotlib pandas networkx\n",
    "```\n",
    "\n",
    "Optional front-end test tools (Jest, Cypress, msw) are documented later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f6b2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2) Imports and reproducible RNG\n",
    "\n",
    "```python\n",
    "import os\n",
    "from datetime import datetime\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "\n",
    "SEED = 42\n",
    "rng = np.random.default_rng(SEED)\n",
    "\n",
    "ARTIFACT_DIR = Path(\"analysis/artifacts/phase7\")\n",
    "ARTIFACT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Environment ready. Seed:\", SEED)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac95c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3) Generate synthetic graphs with annotated edges\n",
    "\n",
    "```python\n",
    "# Build a synthetic graph generator with controlled signals\n",
    "\n",
    "def make_synthetic_graph(num_assets=8, seed=SEED):\n",
    "    rng_local = np.random.default_rng(seed)\n",
    "    G = nx.DiGraph()\n",
    "    assets = [f\"A{i}\" for i in range(num_assets)]\n",
    "    for a in assets:\n",
    "        G.add_node(a)\n",
    "\n",
    "    # Connect assets with some probability and assign synthetic signals\n",
    "    for i in range(num_assets):\n",
    "        for j in range(num_assets):\n",
    "            if i == j:\n",
    "                continue\n",
    "            if rng_local.random() < 0.35:\n",
    "                depth = float(rng_local.uniform(20, 200))  # liquidity depth in units\n",
    "                spread = float(rng_local.uniform(0.0005, 0.01))\n",
    "                vol = float(rng_local.uniform(0.001, 0.05))\n",
    "                failure_rate = float(rng_local.uniform(0.0, 0.2))\n",
    "                G.add_edge(assets[i], assets[j], depth=depth, spread=spread, volatility=vol, failure_rate=failure_rate)\n",
    "    return G\n",
    "\n",
    "# Example graph\n",
    "G = make_synthetic_graph(10)\n",
    "print(f\"Nodes: {G.number_of_nodes()}, Edges: {G.number_of_edges()}\")\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0d3654",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 4) Routing policies: baseline vs SLIL\n",
    "\n",
    "```python\n",
    "# Baseline: shortest path by hop count or by sum(spread)\n",
    "def baseline_route(G, source, dest, mode='spread'):\n",
    "    try:\n",
    "        if mode == 'hop':\n",
    "            return nx.shortest_path(G, source, dest)\n",
    "        elif mode == 'spread':\n",
    "            # weight edges by spread\n",
    "            return nx.shortest_path(G, source, dest, weight=lambda u, v, d: d.get('spread', 1.0))\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "# SLIL: compute a simple path reliability score using a Phase 4 like function\n",
    "# R = 0.4 * normalized_depth - 0.2*spread_scaled - 0.2*vol_scaled - 0.2*failure_rate\n",
    "\n",
    "def edge_score(attrs):\n",
    "    # Normalize heuristically for synthetic data\n",
    "    depth = attrs.get('depth', 0.0)\n",
    "    spread = attrs.get('spread', 0.01)\n",
    "    vol = attrs.get('volatility', 0.01)\n",
    "    failure = attrs.get('failure_rate', 0.1)\n",
    "\n",
    "    depth_norm = np.tanh(depth / 100.0)  # 0..1 like\n",
    "    spread_norm = min(spread / 0.01, 1.0)\n",
    "    vol_norm = min(vol / 0.05, 1.0)\n",
    "    fail_norm = min(failure / 0.2, 1.0)\n",
    "\n",
    "    return 0.4 * depth_norm - 0.2 * spread_norm - 0.2 * vol_norm - 0.2 * fail_norm\n",
    "\n",
    "\n",
    "def slil_route(G, source, dest, max_hops=4):\n",
    "    # enumerate simple paths up to max_hops\n",
    "    try:\n",
    "        paths = list(nx.all_simple_paths(G, source, dest, cutoff=max_hops))\n",
    "    except Exception:\n",
    "        return None\n",
    "    best = None\n",
    "    best_score = -1e9\n",
    "    for p in paths:\n",
    "        # path score = average edge_score\n",
    "        scores = []\n",
    "        ok = True\n",
    "        for u, v in zip(p[:-1], p[1:]):\n",
    "            if not G.has_edge(u, v):\n",
    "                ok = False\n",
    "                break\n",
    "            scores.append(edge_score(G.get_edge_data(u, v)))\n",
    "        if not ok or not scores:\n",
    "            continue\n",
    "        s = sum(scores) / len(scores)\n",
    "        if s > best_score:\n",
    "            best_score = s\n",
    "            best = p\n",
    "    return best\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19dbf20",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 5) Transaction Simulator\n",
    "\n",
    "```python\n",
    "# Simulate a batch of transactions along a path: each edge may fail (probability = failure_rate),\n",
    "# and slippage per edge sampled from N(mean=spread, sd=volatility)\n",
    "\n",
    "def simulate_transactions(G, path, n=50, rng=None):\n",
    "    if not path or len(path) < 2:\n",
    "        return {'successes':0, 'attempts':0, 'avg_slippage':None}\n",
    "    if rng is None:\n",
    "        rng = np.random.default_rng(SEED)\n",
    "    successes = 0\n",
    "    slippages = []\n",
    "    attempts = n\n",
    "    for _ in range(n):\n",
    "        failed = False\n",
    "        total_slip = 0.0\n",
    "        for u, v in zip(path[:-1], path[1:]):\n",
    "            attrs = G.get_edge_data(u, v)\n",
    "            fail_p = attrs.get('failure_rate', 0.1)\n",
    "            if rng.random() < fail_p:\n",
    "                failed = True\n",
    "                break\n",
    "            mean = attrs.get('spread', 0.001)\n",
    "            sd = attrs.get('volatility', 0.01)\n",
    "            slip = max(0.0, rng.normal(mean, sd))\n",
    "            total_slip += slip\n",
    "        if not failed:\n",
    "            successes += 1\n",
    "            slippages.append(total_slip)\n",
    "    avg_slip = float(np.mean(slippages)) if slippages else None\n",
    "    return {'successes':successes, 'attempts':attempts, 'success_rate': successes/attempts if attempts else 0.0, 'avg_slippage':avg_slip}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ba5716",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 6) Monte Carlo experiment: compare baseline vs SLIL\n",
    "\n",
    "```python\n",
    "# Run a small Monte Carlo experiment\n",
    "\n",
    "corridors = []\n",
    "nodes = list(G.nodes())\n",
    "for i in range(len(nodes)):\n",
    "    for j in range(i+1, len(nodes)):\n",
    "        corridors.append((nodes[i], nodes[j]))\n",
    "\n",
    "rng_local = np.random.default_rng(SEED+1)\n",
    "results = []\n",
    "\n",
    "for (src, dst) in corridors:\n",
    "    b_path = baseline_route(G, src, dst, mode='spread')\n",
    "    s_path = slil_route(G, src, dst, max_hops=5)\n",
    "    if not b_path and not s_path:\n",
    "        continue\n",
    "    b_res = simulate_transactions(G, b_path, n=50, rng=rng_local)\n",
    "    s_res = simulate_transactions(G, s_path, n=50, rng=rng_local)\n",
    "    results.append({\n",
    "        'src':src, 'dst':dst,\n",
    "        'baseline_success': b_res.get('success_rate', 0.0), 'baseline_slip': b_res.get('avg_slippage'),\n",
    "        'slil_success': s_res.get('success_rate', 0.0), 'slil_slip': s_res.get('avg_slippage'),\n",
    "        'b_path': b_path, 's_path': s_path\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "print(f\"Completed experiments for {len(df)} corridors\")\n",
    "df.head()\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016306b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 7) Aggregate results and plot summaries\n",
    "\n",
    "```python\n",
    "summary = {\n",
    "    'baseline_avg_success': df['baseline_success'].mean(),\n",
    "    'slil_avg_success': df['slil_success'].mean(),\n",
    "    'baseline_avg_slip': df['baseline_slip'].dropna().mean(),\n",
    "    'slil_avg_slip': df['slil_slip'].dropna().mean(),\n",
    "}\n",
    "print(summary)\n",
    "\n",
    "# Plot success rates\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.hist(df['baseline_success'].dropna(), alpha=0.6, label='Baseline')\n",
    "plt.hist(df['slil_success'].dropna(), alpha=0.6, label='SLIL')\n",
    "plt.legend()\n",
    "plt.title('Distribution of success rates: baseline vs SLIL')\n",
    "plt.xlabel('success rate')\n",
    "plt.ylabel('count')\n",
    "plt.tight_layout()\n",
    "plt.savefig(ARTIFACT_DIR / 'success_rate_hist.png')\n",
    "plt.show()\n",
    "\n",
    "# Scatter of improvement\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.scatter(df['baseline_success'], df['slil_success'])\n",
    "plt.plot([0,1],[0,1], '--', color='gray')\n",
    "plt.xlabel('Baseline success')\n",
    "plt.ylabel('SLIL success')\n",
    "plt.title('SLIL vs Baseline (above diagonal = improvement)')\n",
    "plt.tight_layout()\n",
    "plt.savefig(ARTIFACT_DIR / 'success_scatter.png')\n",
    "plt.show()\n",
    "\n",
    "# Save summary CSV\n",
    "(df.assign(improvement = df['slil_success'] - df['baseline_success']).sort_values('improvement', ascending=False)\n",
    "   .to_csv(ARTIFACT_DIR / 'phase7_summary.csv', index=False))\n",
    "print('Artifacts written to', ARTIFACT_DIR)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd32954e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 8) Reproducibility & manifest\n",
    "\n",
    "```python\n",
    "manifest = {\n",
    "    'git_commit': os.getenv('GIT_COMMIT', 'LOCAL'),\n",
    "    'seed': SEED,\n",
    "    'timestamp': datetime.utcnow().isoformat(),\n",
    "    'summary': summary,\n",
    "}\n",
    "with open(ARTIFACT_DIR / 'manifest.json', 'w') as f:\n",
    "    json.dump(manifest, f, indent=2)\n",
    "\n",
    "print('Manifest written')\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed16d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 9) Diagnostics & Sensitivity\n",
    "\n",
    "```python\n",
    "# Compute per-corridor improvement and diagnostics\n",
    "out_df = df.copy()\n",
    "out_df['improvement'] = out_df['slil_success'] - out_df['baseline_success']\n",
    "num_improved = (out_df['improvement'] > 0).sum()\n",
    "num_total = len(out_df)\n",
    "mean_improvement = out_df['improvement'].mean()\n",
    "print(f\"Corridors improved: {num_improved}/{num_total} ({100.0 * num_improved/num_total:.1f}%)\")\n",
    "print(f\"Mean improvement: {mean_improvement:.4f}\")\n",
    "\n",
    "# Path length comparison\n",
    "out_df['b_len'] = out_df['b_path'].apply(lambda p: len(p)-1 if p else None)\n",
    "out_df['s_len'] = out_df['s_path'].apply(lambda p: len(p)-1 if p else None)\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.hist(out_df['s_len'].dropna() - out_df['b_len'].dropna(), bins=range(-5,6), alpha=0.7)\n",
    "plt.title('Path length difference (SLIL - baseline)')\n",
    "plt.xlabel('edge difference')\n",
    "plt.ylabel('count')\n",
    "plt.tight_layout()\n",
    "plt.savefig(ARTIFACT_DIR / 'path_length_diff.png')\n",
    "plt.show()\n",
    "\n",
    "# Save diagnostics\n",
    "out_df.to_csv(ARTIFACT_DIR / 'phase7_diagnostics.csv', index=False)\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
